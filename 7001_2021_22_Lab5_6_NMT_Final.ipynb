{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZfqzG-psHbd"
      },
      "source": [
        "# **Lab 5 and 6: Neural Machine Translation (Extra Guide)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9GBwu1PsSR3"
      },
      "source": [
        "This week and the next, we'll be build a neural machine translation model based on the sequence-to-sequence (seq2seq) models proposed by Sutskever et al., 2014 and Cho et al., 2014. The seq2seq model is widely used in machine translation systems such as Google’s neural machine translation system (GNMT) (Wu et al., 2016).\n",
        "\n",
        "A folder, **nmt_lab_files** has been provided for you. This folder contains 3 files:\n",
        "1. **data.30.vi** - a file. each line of the file contains a Vietnamese sentence to be translated (i.e. the source sentences). **Source**\n",
        "2. **data.30.en** - a file. each line of the file contains an English sentence corresponding to the Vietnamese sentence in the same line position. (i.e. the target sentences). **Target**\n",
        "3. **nmt_model_keras.py** - the incomplete code for this lab.\n",
        "\n",
        "The doc file provided contains an explanation of the code file and a guide on how to complete the code (by doing 3 tasks). Read the doc file and if you can, complete the code as instructed. When the code is completed, skip to section xx of this notebook. \n",
        "\n",
        "This notebook (prior to section section xx) merely contains further explanation on sections of the code."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coursework disclaimer\n",
        "\n",
        "Note I decided to forego keeping the code as a separate python script and instead opted to transfer the pertinent sections (e.g. attention class, model class, etc.) to this notebook."
      ],
      "metadata": {
        "id": "3SxuPqCNEBrR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uILYujaHHKr_"
      },
      "source": [
        "## Load relevant packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81tHQbRCHKsA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Embedding,LSTM,Dropout,Dense,Layer\n",
        "from keras import Model,Input\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "import collections\n",
        "import numpy as np\n",
        "import time\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyDvxbvTt70n"
      },
      "source": [
        "## **LanguageDict**\n",
        "\n",
        "LanguageDict is a class for creating language dict objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKc_RJ45HKsB"
      },
      "outputs": [],
      "source": [
        "class LanguageDict():\n",
        "  def __init__(self, sents):\n",
        "    word_counter = collections.Counter(tok.lower() for sent in sents for tok in sent)\n",
        "\n",
        "    self.vocab = []\n",
        "    self.vocab.append('<pad>') #zero paddings\n",
        "    self.vocab.append('<unk>')\n",
        "    # add only words that appear at least 10 times in the corpus\n",
        "    self.vocab.extend([t for t,c in word_counter.items() if c > 10])\n",
        "\n",
        "    self.word2ids = {w:id for id, w in enumerate(self.vocab)}\n",
        "    self.ids2word = dict([(value, key) for (key, value) in self.word2ids.items()])\n",
        "    self.UNK = self.word2ids['<unk>']\n",
        "    self.PAD = self.word2ids['<pad>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtHvI1pGvMBG"
      },
      "source": [
        "## **The <load_dataset()> Method**\n",
        "\n",
        "This helper method reads from the source and target files to \n",
        "- load max_num_examples sentences, \n",
        "- split the sentences them into train, development and testing, and\n",
        "- return relevant data.\n",
        "The code for this is fully commented. \n",
        "\n",
        "<br>\n",
        "\n",
        "As an example to the kind of ouput returned by this model, let's assume we are translating the sentence 'I like dogs' from English to English (this of course is never the case), such that the tokenized and case normalized source sentence list and target sentence list are as follows:\n",
        "\n",
        "\n",
        "```\n",
        "# In our case this would actually be [['tôi', 'thích', 'thỏ']], i.e the Vietnamese equivalent of the English sentence. \n",
        "# We've used English to English here so we can follow along with the code.\n",
        "source_words = [['i', 'like', 'rabbits']] \n",
        "target_words = [['i', 'like', 'rabbits']]\n",
        "```\n",
        "The word2ids for the source and target language dictionaries would look something like:\n",
        "```\n",
        "source_dict.word2ids = {'<PAD>': 0, '<UNK>': 1, 'i': 2, 'like': 3, 'rabbits':4}\n",
        "\n",
        "# end and start tokens are added for the target words\n",
        "target_dict.word2ids = {'<PAD>': 0, '<UNK>': 1, '<start>': 2, 'i': 3, 'like': 4, 'rabbits':5, '<end>':6}\n",
        "\n",
        "```\n",
        "Let's also assume that we are training and testing on this same dataset of one sentence.\n",
        "The **source words** for train/dev/test will be given as\n",
        "```\n",
        "# a batch_size X max_sent_length array.\n",
        "source_words_train = [[2,3,4]] # corresponding to ['i', 'like', 'rabbits']\n",
        "source_words_dev = [[2,3,4]]  # corresponding to ['i', 'like', 'rabbits']\n",
        "source_words_test = [[2,3,4]] # corresponding to ['i', 'like', 'rabbits']\n",
        "```\n",
        "\n",
        "The **target words** for train data will be given as follows (dev/test don't need target words as the model will provide this):\n",
        "```\n",
        "target_words_train = [[2,3,4,5]] # corresponding to ['<start>', 'i', 'like', 'rabbits']\n",
        "```\n",
        "\n",
        "The **target words labels** for each word will be the word after it. The target word labels for train/dev/test data will be given as follows\n",
        "```\n",
        "target_words_train_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
        "target_words_dev_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
        "target_words_test_labels = [[3,4,5,6]] # corresponding to ['i', 'like', 'rabbits', '<end>']\n",
        "```\n",
        "The dimensions for train target words labels would be expanded to this:\n",
        "`[[3], [4], [5], [6]]`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dT-LpD29HKsE"
      },
      "outputs": [],
      "source": [
        "def load_dataset(source_path,target_path, max_num_examples=30000):\n",
        "  ''' This helper method reads from the source and target files to load max_num_examples \n",
        "  sentences, split them into train, development and testing and return relevant data.\n",
        "  Inputs:\n",
        "    source_path (string): the full path to the source data, SOURCE_PATH\n",
        "    target_path (string): the full path to the target data, TARGET_PATH\n",
        "  Returns:\n",
        "    train_data (list): a list of 3 elements: source_words, target words, target word labels\n",
        "    dev_data (list): a list of 2 elements - source words, target word labels\n",
        "    test_data (list): a list of 2 elements - source words, target word labels\n",
        "    source_dict (LanguageDict): a LanguageDict object for the source language, Vietnamese.\n",
        "    target_dict (LanguageDict): a LanguageDict object for the target language, English.\n",
        "  ''' \n",
        "  # source_lines/target lines are list of strings such that each string is a sentence in the\n",
        "  # corresponding file. len(source/target_lines) <= max_num_examples\n",
        "  source_lines = open(source_path).readlines()\n",
        "  target_lines = open(target_path).readlines()\n",
        "  assert len(source_lines) == len(target_lines)\n",
        "  if max_num_examples > 0:\n",
        "    max_num_examples = min(len(source_lines), max_num_examples)\n",
        "    source_lines = source_lines[:max_num_examples]\n",
        "    target_lines = target_lines[:max_num_examples]\n",
        "\n",
        "  # strip trailing/leading whitespaces and tokenize each sentence. \n",
        "  source_sents = [[tok.lower() for tok in sent.strip().split(' ')] for sent in source_lines]\n",
        "  target_sents = [[tok.lower() for tok in sent.strip().split(' ')] for sent in target_lines]\n",
        "    # for the target sentences, add <start> and <end> tokens to each sentence \n",
        "  for sent in target_sents:\n",
        "    sent.append('<end>')\n",
        "    sent.insert(0,'<start>')\n",
        "\n",
        "  # create the LanguageDict objects for each file\n",
        "  source_lang_dict = LanguageDict(source_sents)\n",
        "  target_lang_dict = LanguageDict(target_sents)\n",
        "\n",
        "\n",
        "  # for the source sentences.\n",
        "  # we'll use this to split into train/dev/test \n",
        "  unit = len(source_sents)//10\n",
        "  # get the sents-as-ids for each sentence\n",
        "  source_words = [[source_lang_dict.word2ids.get(tok,source_lang_dict.UNK) for tok in sent] for sent in source_sents]\n",
        "  # 8 parts (80%) of the sentences go to the training data. pad upto maximum sentence length\n",
        "  source_words_train = pad_sequences(source_words[:8*unit],padding='post')\n",
        "  # 1 parts (10%) of the sentences go to the dev data. pad upto maximum sentence length\n",
        "  source_words_dev = pad_sequences(source_words[8*unit:9*unit],padding='post')\n",
        "  # 1 parts (10%) of the sentences go to the test data. pad upto maximum sentence length\n",
        "  source_words_test = pad_sequences(source_words[9*unit:],padding='post')\n",
        "\n",
        "\n",
        "  eos = target_lang_dict.word2ids['<end>']\n",
        "  # for each sentence, get the word index for the tokens from <start> to up to but not including <end>,\n",
        "  target_words = [[target_lang_dict.word2ids.get(tok,target_lang_dict.UNK) for tok in sent[:-1]] for sent in target_sents]\n",
        "  # select the training set and pad the sentences\n",
        "  target_words_train = pad_sequences(target_words[:8*unit],padding='post')\n",
        "  # the label for each target word is the next word after it\n",
        "  target_words_train_labels = [sent[1:]+[eos] for sent in target_words[:8*unit]]\n",
        "  # pad the labels. Dim = [num_sents, max_sent_lenght]\n",
        "  target_words_train_labels = pad_sequences(target_words_train_labels,padding='post')\n",
        "  # expand dimensions Dim = [num_sents, max_sent_lenght, 1]. \n",
        "  target_words_train_labels = np.expand_dims(target_words_train_labels,axis=2)\n",
        "\n",
        "  # get the labels for the dev and test data. No need for inputs here. no need to expand dimensions\n",
        "  target_words_dev_labels = pad_sequences([sent[1:] + [eos] for sent in target_words[8 * unit:9 * unit]], padding='post')\n",
        "  target_words_test_labels = pad_sequences([sent[1:] + [eos] for sent in target_words[9 * unit:]], padding='post')\n",
        "\n",
        "  # we have our data.\n",
        "  train_data = [source_words_train,target_words_train,target_words_train_labels]\n",
        "  dev_data = [source_words_dev,target_words_dev_labels]\n",
        "  test_data = [source_words_test,target_words_test_labels]\n",
        "\n",
        "  return train_data,dev_data,test_data,source_lang_dict,target_lang_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the datasets\n",
        "\n",
        "Let's load the datasets using the load function defined earlier."
      ],
      "metadata": {
        "id": "USRjON2zDCr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_path = \"data.30.vi\"\n",
        "target_path = \"data.30.en\"\n",
        "\n",
        "train_data,dev_data,test_data,source_lang_dict,target_lang_dict = load_dataset(source_path,target_path, max_num_examples=30000)"
      ],
      "metadata": {
        "id": "-TO4SRGVKP_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's now quickly check the data structure."
      ],
      "metadata": {
        "id": "uWwbX8TkDcg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of training set: {len(train_data)}\")\n",
        "\n",
        "print(\"source_words\")\n",
        "print(train_data[0][0])\n",
        "print([source_lang_dict.ids2word[word] for word in train_data[0][0]])\n",
        "print(\"target words\")\n",
        "print(train_data[0][1])\n",
        "print([target_lang_dict.ids2word[word] for word in train_data[0][1]])\n",
        "print(\"target word labels\")\n",
        "print([target_lang_dict.ids2word[word] for word in train_data[0][2]])"
      ],
      "metadata": {
        "id": "oBMMTTPaK9Zd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada5c72d-249b-47a5-803a-392272f76797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training set: 3\n",
            "source_words\n",
            "[ 2  3  4  5  6  7  8  9 10 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0]\n",
            "['khoa', 'học', 'đằng', 'sau', 'một', 'tiêu', 'đề', 'về', 'khí', 'hậu', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "target words\n",
            "[12 13 14 15 16 17  9 18 19 20 21 22 23 24  2  3 25 26 27 28 29 15 30  1\n",
            " 16 31 32 33 34 35]\n",
            "['like', 'to', 'talk', 'you', 'today', 'about', '<end>', 'scale', 'of', 'scientific', 'effort', 'that', 'goes', 'into', '<start>', ':', 'making', 'see', 'in', 'paper', '.', 'you', 'they', '<unk>', 'today', 'are', 'both', 'two', 'same', 'field']\n",
            "target word labels\n",
            "['was', 'written', 'by', 'scientists', 'behind', '<unk>', 'effort', 'from', 'behind', '40', 'countries', 'wrote', 'almost', '<start>', ':', 'i', 'thousand', 'field', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_data[0]"
      ],
      "metadata": {
        "id": "2nz6u_08LJG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5ce653-dc21-4f88-8cf7-9ee905408f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 111,  963,  706, ...,    0,    0,    0],\n",
              "       [ 334,  128,  181, ...,    0,    0,    0],\n",
              "       [1393,   48,  106, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 334,  144,   63, ...,    0,    0,    0],\n",
              "       [ 110,   75,   52, ...,    0,    0,    0],\n",
              "       [1689, 1072,  432, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "MzvUs76lLMJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3569a813-5ab0-47b8-bfe2-b235457667ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[1689, 1072,  343, ...,    0,    0,    0],\n",
              "        [ 238,  545,   29, ...,    0,    0,    0],\n",
              "        [ 238,  190,  191, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [  64,   22,  190, ...,    0,    0,    0],\n",
              "        [ 651,  652,  102, ...,    0,    0,    0],\n",
              "        [  64,   22,  190, ...,    0,    0,    0]], dtype=int32),\n",
              " array([[   4,  260, 1865, ...,    0,    0,    0],\n",
              "        [  74,  483, 1296, ...,    0,    0,    0],\n",
              "        [ 100,   75,  124, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [  49,  100,   15, ...,    0,    0,    0],\n",
              "        [ 462,  829,   22, ...,    0,    0,    0],\n",
              "        [  49,  100,   15, ...,    0,    0,    0]], dtype=int32)]"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc8KZaJn3uBK"
      },
      "source": [
        "## **The Neural Translation Model (NMT)**\n",
        "\n",
        "For the NMT the network (a system of connected layers/models) used for training differs slightly from the network used for inference. Both use the the seq-to-seq encoder-decoder architecture. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgtz6XAl4E8D"
      },
      "source": [
        "### **The training mode**\n",
        "\n",
        "**Encoder**\n",
        "\n",
        "Given:\n",
        "- `source_words`: a `batch_size(num_sents) x max_sentence_length` array representing the source words. In our mini example, this would be the Vietnamese equivalent of `['i', 'like', 'rabbits']`; `[['tôi', 'thích', 'thỏ']]`\n",
        "\n",
        "The following steps comprise the encoding network:\n",
        "\n",
        "1. transform `source_words` into `source_words_embeddings` using a randomly initialized embedding lookup. source_words_embeddings is thus a `batch_size(num_sents) x max_sentence_length x embedding_dim` array.\n",
        "2. Apply embedding dropout of `embedding_dropout_rate`.\n",
        "3. Use a single `LSTM` with `hidden_size` units to learn a representation for the source words i.e. to encode the input. \n",
        "\n",
        "    (a.) The hidden and cell states for this `LSTM` are initialized to zeros (i.e. we leave the `initial_states = None` default as is).\n",
        "\n",
        "    (b.) We save the `encoder_output` (the sequence not just the last state); and the encoder (hidden and cell) states. \n",
        "\n",
        "This way, the model encodes a representation for the source words. Task 1 guides you to complete the encoder part of the training model.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Decoder (No Attention)**\n",
        "\n",
        "Given:\n",
        "- `target_words`: a `batch_size(i.e.num_sents in batch) x max_sentence_length+1` array representing the target words. This is a time shifted translation of the source words with an added (prepended) `<START>` token `['<start>', 'i', 'like', 'rabbits']`.\n",
        "\n",
        "The decoding is in the following steps:\n",
        "\n",
        "1. transform `target_words` into `target_words_embeddings` using a randomly initialized embedding lookup. target_words_embeddings is thus a `batch_size x max_sentence_length+1 x embedding_dim` array.\n",
        "\n",
        "2.  Apply embedding dropout of `embedding_dropout_rate`.\n",
        "\n",
        "3. Use a single `LSTM` with `hidden_size` units to learn a representation for the target words. Some context is given to this model by using the encoder states to initialize the decoder lstm. This way the encoder state for `'tôi'` for example is used to learn to the representation (and next word prediction, see number 4.) for the `'<start>'` token, and so on.\n",
        "\n",
        "4. For each token representation, use a dense layer to predict a `target_vocab_size` vector which is the probability that any given word in the target vocabulary is the next word following the represented token. The output `decoder_outputs_train` is thus a `batch_size x max_sent_length x target_vocab_size` array.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4tsMpCYJUk1"
      },
      "source": [
        "### **The Inference Mode**\n",
        "\n",
        "**Encoder**\n",
        "\n",
        "The inference time encoding follows the same steps as training time encoding.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Decoder (No attention)**\n",
        "\n",
        "During training time, we passed a `batch_size(num_sents) x max_sentence_length` array representing the target words into the decoder lstm. The decoder_lstm learns how to represent a given target sentence using the context from the encoder lstm (that learns to represent a source sentence).  \n",
        "\n",
        "At test time, several things are different:\n",
        "\n",
        "1. We no longer have access to a complete translation of the source sentence (recall that no target_words array exists for dev and test sets). Rather, we initialize the target_words_array as thus:\n",
        "\n",
        "    Each expected sentence contains only a single token index, the index of the `'<start>'` token. So, the target_word_dev/test is a `batch_size x 1` array. (see the nmt.eval() function for this)\n",
        "\n",
        "2. This `batch_size x 1` array is fed to the trained decoder_lstm and the predicted array is a `batch_size x 1 x target_vocab_size` such that taking the argmax of this array accross the dimension 2 will give the most probable next word. \n",
        "\n",
        "    For example, at time_step `0`, the first time step, where the `step_target_words` given is the `batch_size x 1` array containing the `'<start>'` token, the next word prediction of the decoder is for each sentence (in the batch) the initial word in the sentence. \n",
        "\n",
        "3. At the first time step, the decoder_lstm still uses the encoder_states as it's initial states. At subsequent time steps, it uses it's own states from the previous time steps. This is also what the decoder_lstm does at training time but it is made more explicit here as we loop over time steps using a for loop.\n",
        "(see nmt.eval())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention\n",
        "**encoder_outputs** has a shape of [batch_size, **max_source_sent_len**,\n",
        "hidden_size]\n",
        "\n",
        "**decoder_outputs** has a shape of [batch_size,\n",
        "**max_target_sent_len**, hidden_size]"
      ],
      "metadata": {
        "id": "Qqc5jeRYaqtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(Layer):\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    if mask == None:\n",
        "      return None\n",
        "    return mask[1]\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return (input_shape[1][0],input_shape[1][1],input_shape[1][2]*2)\n",
        "\n",
        "\n",
        "  def call(self, inputs, mask=None):\n",
        "    encoder_outputs, decoder_outputs = inputs\n",
        "\n",
        "    \"\"\"\n",
        "    Task 3 attention\n",
        "    \n",
        "    Start\n",
        "    \"\"\"\n",
        "\n",
        "    #=======================================#\n",
        "    #the transpose of the last 2 dimensions.\n",
        "    #=======================================# \n",
        "    # Note the first dimension is the batch size and shouldn't be touched.\n",
        "    \n",
        "    decoder_outputs_T =  K.permute_dimensions(decoder_outputs,(0,2,1)) #out: [batch_size, hidden_size, max_target_sent_len]\n",
        "\n",
        "    #=========================================#\n",
        "    #Dot of encoder outputs and decoder outputs\n",
        "    #=========================================#\n",
        "    # axes = [2,1] represents [hidden layer of encoder_outputs, hidden layer of decoder_outputs]\n",
        "    # = [2nd dimension of encoder outputs, 3rd dimension of the transpose of the decoder outputs]\n",
        "    luong_score = K.batch_dot(encoder_outputs,\n",
        "                        decoder_outputs_T,\n",
        "                        axes =[2,1]) # out: [batch_size, max_source_sent_len, max_target_sent_len]\n",
        "\n",
        "    #==========================================================#\n",
        "    #perform softmax to get the probability distribution/weights\n",
        "    #==========================================================#\n",
        "    luong_score_softmax = K.softmax(luong_score, axis=1)\n",
        "\n",
        "    #=========================================#\n",
        "    #Prepare inputs of weighted sum (expansion)\n",
        "    #=========================================# \n",
        "\n",
        "    # We do this because python will later broadcast during matrix multiplication\n",
        "    luong_score_softmax_expand = K.expand_dims(luong_score_softmax,-1) # out [batch_size, max_source_sent_len, max_target_sent_len, 1]\n",
        "\n",
        "    encoder_outputs_expand = K.expand_dims(encoder_outputs,2) # out [batch_size, max_source_sent_len, 1, hidden_size]\n",
        "\n",
        "    #=============================#\n",
        "    #Attention score (weighted sum)\n",
        "    #=============================#\n",
        "\n",
        "    #Finally we are going to create the encoder_vector by doing element-wise multiplication\n",
        "\n",
        "    product = encoder_outputs_expand*luong_score_softmax_expand\n",
        "\n",
        "    #The last step is to sum the max_source_sent_len dimension to create the encoder_vector.\n",
        "    encoder_vector = K.sum(product,axis = 1)\n",
        "    \n",
        "    \"\"\"\n",
        "    End Task 3\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "    # [batch,max_dec,2*hidden size]\n",
        "    new_decoder_outputs = K.concatenate([decoder_outputs, encoder_vector])\n",
        "\n",
        "    return new_decoder_outputs"
      ],
      "metadata": {
        "id": "bKZAwXt4Pevu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NmtModel(object):\n",
        "  def __init__(self,source_dict,target_dict,use_attention):\n",
        "    ''' The model initialization function initializes network parameters.\n",
        "    Inputs:\n",
        "      source_dict (LanguageDict): a LanguageDict object for the source language, Vietnamese.\n",
        "      target_dict (LanguageDict): a LanguageDict object for the target language, English.\n",
        "      use_attention (bool): if True, use attention.\n",
        "    Returns:\n",
        "      None.\n",
        "    '''\n",
        "    # the number of hidden units used by the LSTM\n",
        "    self.hidden_size = 200\n",
        "    # the size of the word embeddings being used\n",
        "    self.embedding_size = 100\n",
        "    # the dropout rate for the hidden layers\n",
        "    self.hidden_dropout_rate=0.2\n",
        "    # the dropout rate for the word embeddings\n",
        "    self.embedding_dropout_rate = 0.2\n",
        "    # batch size\n",
        "    self.batch_size = 100\n",
        "\n",
        "    # the maximum length of the target sentences\n",
        "    #Used in the inference step\n",
        "    self.max_target_step = 30\n",
        "\n",
        "    # vocab size for source and target; we'll use everything we receive\n",
        "    self.vocab_target_size = len(target_dict.vocab)\n",
        "    self.vocab_source_size = len(source_dict.vocab)\n",
        "\n",
        "    # instances of the dictionaries\n",
        "    self.target_dict = target_dict\n",
        "    self.source_dict = source_dict\n",
        "\n",
        "    # special tokens to indicate sentence starts and ends.\n",
        "    self.SOS = target_dict.word2ids['<start>']\n",
        "    self.EOS = target_dict.word2ids['<end>']\n",
        "\n",
        "    # Boolean to use attention or not\n",
        "    # use attention or no\n",
        "    self.use_attention = use_attention\n",
        "\n",
        "    print(\"number of tokens in source: %d, number of tokens in target:%d\" % (self.vocab_source_size,self.vocab_target_size))\n",
        "\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "\n",
        "    #-------------------------Train Models------------------------------\n",
        "    source_words = Input(shape=(None,),dtype='int32')\n",
        "    target_words = Input(shape=(None,), dtype='int32')\n",
        "\n",
        "    \"\"\"\n",
        "    Task 1 encoder\n",
        "    \n",
        "    Start\n",
        "    \"\"\"\n",
        "    # The train encoder\n",
        "    # (a.) Create two randomly initialized embedding lookups, one for the source, another for the target. \n",
        "    print('Task 1(a): Creating the embedding lookups...')\n",
        "    embeddings_source = Embedding(self.vocab_source_size, self.embedding_size, name='embedding_source', #Note the first argument here is the vocabulary size\n",
        "                        \tembeddings_initializer='glorot_uniform', mask_zero=True, trainable=True)\n",
        "    embeddings_target = Embedding(self.vocab_target_size, self.embedding_size, name='embedding_target', #Note the first argument here is the vocabulary size\n",
        "                        \tembeddings_initializer='glorot_uniform', mask_zero=True, trainable=True) \n",
        "    \n",
        "    # (b.) Look up the embeddings for source words and for target words. Apply dropout to each encoded input\n",
        "    print('\\nTask 1(b): Looking up source and target words...')\n",
        "    source_word_embeddings = embeddings_source(source_words)\n",
        "    target_words_embeddings = embeddings_target(target_words)\n",
        "\n",
        "    source_word_embeddings = Dropout(self.embedding_dropout_rate, \n",
        "                             input_shape = source_word_embeddings.shape, \n",
        "                             name = \"dropout_source_embedding\",seed=1010)(source_word_embeddings)\n",
        "\n",
        "    target_words_embeddings = Dropout(self.embedding_dropout_rate, \n",
        "                          input_shape = source_word_embeddings.shape, \n",
        "                          name = \"dropout_target_embedding\",seed=1010)(target_words_embeddings)\n",
        "\n",
        "\n",
        "\n",
        "    # (c.) An encoder LSTM() with return sequences set to True\n",
        "    print('\\nTask 1(c): Creating an encoder')\n",
        "    encoder_lstm = LSTM(self.hidden_size, return_sequences = True, return_state = True, name = \"encoder_LSTM\")\n",
        "\n",
        "    # encoder_outputs = hidden state at every time step\n",
        "    # encoder_state_h = hidden_state at final time_step\n",
        "    # encoder_state_c = cell state\n",
        "\n",
        "    encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(source_word_embeddings)\n",
        "    \"\"\"\n",
        "    End Task 1\n",
        "    \"\"\"\n",
        "    encoder_states = [encoder_state_h,encoder_state_c]\n",
        "\n",
        "    # The train decoder\n",
        "    decoder_lstm = LSTM(self.hidden_size, recurrent_dropout=self.hidden_dropout_rate, \n",
        "                        return_sequences=True, return_state=True, name = \"decoder_LSTM\")\n",
        "    decoder_outputs_train,_,_ = decoder_lstm(target_words_embeddings,initial_state=encoder_states)\n",
        "\n",
        "    if self.use_attention:\n",
        "      decoder_attention = AttentionLayer()\n",
        "      decoder_outputs_train = decoder_attention([encoder_outputs,decoder_outputs_train])\n",
        "\n",
        "    decoder_dense = Dense(self.vocab_target_size,activation='softmax')\n",
        "    decoder_outputs_train = decoder_dense(decoder_outputs_train)\n",
        "\n",
        "    # compiling the train model.\n",
        "    adam = Adam(lr=0.01,clipnorm=5.0)\n",
        "    self.train_model = Model([source_words,target_words], decoder_outputs_train)\n",
        "    self.train_model.compile(optimizer=adam,loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # at this point you can print model summary for the train model\n",
        "    print('\\t\\t\\t\\t\\t\\t Train Model Summary.')\n",
        "    self.train_model.summary()\n",
        "\n",
        "\n",
        "\n",
        "    #-------------------------Inference Models------------------------------\n",
        "    # The inference encoder \n",
        "    self.encoder_model = Model(source_words,[encoder_outputs,encoder_state_h,encoder_state_c])\n",
        "    # at this point you can print the summary for the encoder model.\n",
        "    print('\\t\\t\\t\\t\\t\\t Inference Time Encoder Model Summary.')\n",
        "    self.encoder_model.summary()\n",
        "\n",
        "    # The decoder model\n",
        "    # specifying the inputs to the decoder\n",
        "    decoder_state_input_h = Input(shape=(self.hidden_size,)) # last hidden State\n",
        "    decoder_state_input_c = Input(shape=(self.hidden_size,)) # cell state\n",
        "    encoder_outputs_input = Input(shape=(None,self.hidden_size,)) # encoder outputs\n",
        "\n",
        "    \"\"\"\n",
        "    Task 2 decoder for inference\n",
        "    \n",
        "    Start\n",
        "    \"\"\"\n",
        "    # Task 2 (a.) Get the decoded outputs\n",
        "    print('\\n Putting together the decoder states')\n",
        "    # get the initial states for the decoder, decoder_states\n",
        "    # decoder states are the hidden and cell states from the training stage\n",
        "\n",
        "\n",
        "    decoder_states = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    # use decoder states as input to the decoder lstm to get the decoder outputs, h, and c for test time inference\n",
        "    decoder_outputs_test,decoder_state_output_h, decoder_state_output_c = decoder_lstm(target_words_embeddings,\n",
        "                                                                                       initial_state = decoder_states)\n",
        "\n",
        "\n",
        "    # Task 2 (b.) Add attention if attention\n",
        "    if self.use_attention:\n",
        "      decoder_outputs_test = decoder_attention([encoder_outputs_input, \n",
        "                                                decoder_outputs_test])\n",
        "\n",
        "    # Task 2 (c.) pass the decoder_outputs_test (with or without attention) to the decoder dense layer\n",
        "    \n",
        "    decoder_outputs_test = decoder_dense(decoder_outputs_test)\n",
        "\n",
        "    \"\"\"\n",
        "    End Task 2 \n",
        "    \"\"\"\n",
        "    # put the model together\n",
        "    self.decoder_model = Model([target_words,decoder_state_input_h,decoder_state_input_c,encoder_outputs_input],\n",
        "                               [decoder_outputs_test,decoder_state_output_h,decoder_state_output_c])\n",
        "    # you can now view the model summary\n",
        "    print('\\t\\t\\t\\t\\t\\t Decoder Inference Model summary')\n",
        "    print(self.decoder_model.summary())\n",
        "\n",
        "\n",
        "\n",
        "  def time_used(self, start_time):\n",
        "    curr_time = time.time()\n",
        "    used_time = curr_time-start_time\n",
        "    m = used_time // 60\n",
        "    s = used_time - 60 * m\n",
        "    return \"%d m %d s\" % (m, s)\n",
        "\n",
        "\n",
        "\n",
        "  def train(self,train_data,dev_data,test_data, epochs):\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "      print(\"Starting training epoch {}/{}\".format(epoch + 1, epochs))\n",
        "      epoch_time = time.time()\n",
        "      source_words_train, target_words_train, target_words_train_labels = train_data\n",
        "\n",
        "      self.train_model.fit([source_words_train,target_words_train],target_words_train_labels,batch_size=self.batch_size)\n",
        "\n",
        "      print(\"Time used for epoch {}: {}\".format(epoch + 1, self.time_used(epoch_time)))\n",
        "      dev_time = time.time()\n",
        "      print(\"Evaluating on dev set after epoch {}/{}:\".format(epoch + 1, epochs))\n",
        "      self.eval(dev_data)\n",
        "      print(\"Time used for evaluate on dev set: {}\".format(self.time_used(dev_time)))\n",
        "\n",
        "    print(\"Training finished!\")\n",
        "    print(\"Time used for training: {}\".format(self.time_used(start_time)))\n",
        "\n",
        "    print(\"Evaluating on test set:\")\n",
        "    test_time = time.time()\n",
        "    self.eval(test_data)\n",
        "    print(\"Time used for evaluate on test set: {}\".format(self.time_used(test_time)))\n",
        "\n",
        "\n",
        "\n",
        "  def get_target_sentences(self, sents,vocab,reference=False):\n",
        "    str_sents = []\n",
        "    num_sent, max_len = sents.shape\n",
        "    for i in range(num_sent):\n",
        "      str_sent = []\n",
        "      for j in range(max_len):\n",
        "        t = sents[i,j].item()\n",
        "        if t == self.SOS:\n",
        "          continue\n",
        "        if t == self.EOS:\n",
        "          break\n",
        "\n",
        "        str_sent.append(vocab[t])\n",
        "      if reference:\n",
        "        str_sents.append([str_sent])\n",
        "      else:\n",
        "        str_sents.append(str_sent)\n",
        "    return str_sents\n",
        "\n",
        "\n",
        "\n",
        "  def eval(self, dataset,print_outputs = False):\n",
        "    # get the source words and target_word_labels for the eval dataset\n",
        "    source_words, target_words_labels = dataset\n",
        "    vocab = self.target_dict.vocab\n",
        "\n",
        "    # using the same encoding network used during training time, encode the training\n",
        "    encoder_outputs, state_h,state_c = self.encoder_model.predict(source_words,batch_size=self.batch_size)\n",
        "    # for max_target_step steps, feed the step target words into the decoder.\n",
        "    predictions = []\n",
        "    step_target_words = np.ones([source_words.shape[0],1]) * self.SOS #start with <Start> symbol, initialized as a vector of <Start> symbols\n",
        "    for _ in range(self.max_target_step):\n",
        "      \n",
        "      step_decoder_outputs, state_h,state_c = self.decoder_model.predict([step_target_words,state_h,state_c,encoder_outputs],batch_size=self.batch_size)\n",
        "      step_target_words = np.argmax(step_decoder_outputs,axis=2)\n",
        "      predictions.append(step_target_words)\n",
        "\n",
        "    # predictions is a [time_step x batch_size x 1] array. We use get_target_sentence() to recover the batch_size sentences\n",
        "    candidates = self.get_target_sentences(np.concatenate(predictions,axis=1),vocab)\n",
        "    references = self.get_target_sentences(target_words_labels,vocab,reference=True)\n",
        "\n",
        "    # score using nltk bleu scorer\n",
        "    score = corpus_bleu(references,candidates)\n",
        "    print(\"Model BLEU score: %.2f\" % (score*100.0))\n",
        "\n",
        "    #Modification\n",
        "    if print_outputs:\n",
        "      sources = self.get_target_sentences(np.array(source_words[0:len(source_words)]),self.source_dict.vocab)\n",
        "      return sources,  candidates, references\n",
        "\n"
      ],
      "metadata": {
        "id": "P5wGe0ZWOQ4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output printing function\n",
        "\n",
        "This function prints out a set number of translation from the test set. This is done by modifying the `eval()` function in the model class and adding a parameters that allows it to output the follow:\n",
        "\n",
        "1. Sources = Source sentences in the test set\n",
        "2. Candidates = predicted translations\n",
        "3. References = actual translations\n",
        "\n",
        "One important thing to note is that there may be <UNK> tokens in any of these lists. This is because the language dictionary is based on the training set, hence some tokens in the test sight might not be included.\n",
        "\n",
        "Moreover, the presence of an <UNK> in the predicted translation is because that token had the highest probability of being the next word. This is a byproduct of using greedy inference. One way to fix this would be to apply some mechanism to replace <UNK> tokens (e.g. get the 2nd most likely token), or to use a different type of inference altogether (e.g. beam search)."
      ],
      "metadata": {
        "id": "oacA9EDVFjuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_examples(model, example_no = 10):\n",
        "  \"\"\"\n",
        "  Prints out a set number of translations from the test set\n",
        "  \"\"\"\n",
        "\n",
        "  sources,  candidates, references = model.eval(test_data,print_outputs=True)\n",
        "\n",
        "  for i in range(example_no-1):\n",
        "\n",
        "    print(f\"example:{i+1}\")\n",
        "    print(f\"Source sentence: {' '.join(sources[i]).replace('<pad>', '')}\")\n",
        "    print(f\"Predicted translation: {' '.join(candidates[i]).replace('<pad>', '')}\")\n",
        "    print(f\"Actual translation: {' '.join([l[0] for l in references][i]).replace('<pad>', '')}\")"
      ],
      "metadata": {
        "id": "Hl-9IDIjy0pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(source_path, target_path, use_attention):\n",
        "  max_example = 30000\n",
        "  print('loading dictionaries')\n",
        "  train_data, dev_data, test_data, source_dict, target_dict = load_dataset(source_path,target_path,max_num_examples=max_example)\n",
        "  print(\"read %d/%d/%d train/dev/test batches\" % (len(train_data[0]),len(dev_data[0]), len(test_data[0])))\n",
        "\n",
        "  model = NmtModel(source_dict,target_dict,use_attention)\n",
        "  model.build()\n",
        "  model.train(train_data,dev_data,test_data,10)"
      ],
      "metadata": {
        "id": "OzUyrrfWgg2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFIKOF5sed68"
      },
      "source": [
        "## **Training Without Attention**\n",
        "\n",
        "If you've completed Tasks 1 and 2, you are ready to train the NMT model without attention.\n",
        "\n",
        "Run the following cells to train the model for 10 epochs. It also shows the model summary of the each model you encapsulated.\n",
        "\n",
        "If you're using a GPU, training will no more than 10 minutes and you will get a BLEU score between 4 and 5. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "jHF5BUXS1Rqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clear session prior to creating the architecture\n",
        "tf.keras.backend.clear_session()\n",
        "model = NmtModel(source_lang_dict, target_lang_dict,False)\n",
        "model.build()"
      ],
      "metadata": {
        "id": "IzYr4j4kfwpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfbb150-feaf-435a-dee9-00545a033c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of tokens in source: 2034, number of tokens in target:2506\n",
            "Task 1(a): Creating the embedding lookups...\n",
            "\n",
            "Task 1(b): Looking up source and target words...\n",
            "\n",
            "Task 1(c): Creating an encoder\n",
            "WARNING:tensorflow:Layer decoder_LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "\t\t\t\t\t\t Train Model Summary.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_source (Embedding)   (None, None, 100)    203400      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_target (Embedding)   (None, None, 100)    250600      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_source_embedding (Drop  (None, None, 100)   0           ['embedding_source[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_target_embedding (Drop  (None, None, 100)   0           ['embedding_target[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " encoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_source_embedding[0][0]'\n",
            "                                 (None, 200),                    ]                                \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " decoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_target_embedding[0][0]'\n",
            "                                 (None, 200),                    , 'encoder_LSTM[0][1]',          \n",
            "                                 (None, 200)]                     'encoder_LSTM[0][2]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 2506)   503706      ['decoder_LSTM[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,439,306\n",
            "Trainable params: 1,439,306\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_source (Embedding  (None, None, 100)        203400    \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_source_embedding (D  (None, None, 100)        0         \n",
            " ropout)                                                         \n",
            "                                                                 \n",
            " encoder_LSTM (LSTM)         [(None, None, 200),       240800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 444,200\n",
            "Trainable params: 444,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Putting together the decoder states\n",
            "\t\t\t\t\t\t Decoder Inference Model summary\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_target (Embedding)   (None, None, 100)    250600      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_target_embedding (Drop  (None, None, 100)   0           ['embedding_target[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " decoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_target_embedding[0][0]'\n",
            "                                 (None, 200),                    , 'input_3[0][0]',               \n",
            "                                 (None, 200)]                     'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, None, 200)]  0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 2506)   503706      ['decoder_LSTM[1][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 995,106\n",
            "Trainable params: 995,106\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and test evaluation "
      ],
      "metadata": {
        "id": "weEqKtoL1V7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(train_data,dev_data,test_data,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLPR2578voFd",
        "outputId": "b336e794-e73d-4b04-ac14-413f9bb114aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training epoch 1/10\n",
            "240/240 [==============================] - 19s 60ms/step - loss: 2.1202 - accuracy: 0.2449\n",
            "Time used for epoch 1: 0 m 18 s\n",
            "Evaluating on dev set after epoch 1/10:\n",
            "Model BLEU score: 1.54\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 2/10\n",
            "240/240 [==============================] - 15s 61ms/step - loss: 1.8235 - accuracy: 0.3032\n",
            "Time used for epoch 2: 0 m 14 s\n",
            "Evaluating on dev set after epoch 2/10:\n",
            "Model BLEU score: 2.25\n",
            "Time used for evaluate on dev set: 0 m 6 s\n",
            "Starting training epoch 3/10\n",
            "240/240 [==============================] - 15s 61ms/step - loss: 1.7040 - accuracy: 0.3362\n",
            "Time used for epoch 3: 0 m 20 s\n",
            "Evaluating on dev set after epoch 3/10:\n",
            "Model BLEU score: 3.56\n",
            "Time used for evaluate on dev set: 0 m 6 s\n",
            "Starting training epoch 4/10\n",
            "240/240 [==============================] - 14s 60ms/step - loss: 1.6276 - accuracy: 0.3544\n",
            "Time used for epoch 4: 0 m 14 s\n",
            "Evaluating on dev set after epoch 4/10:\n",
            "Model BLEU score: 3.80\n",
            "Time used for evaluate on dev set: 0 m 6 s\n",
            "Starting training epoch 5/10\n",
            "240/240 [==============================] - 15s 61ms/step - loss: 1.5736 - accuracy: 0.3643\n",
            "Time used for epoch 5: 0 m 14 s\n",
            "Evaluating on dev set after epoch 5/10:\n",
            "Model BLEU score: 4.18\n",
            "Time used for evaluate on dev set: 0 m 6 s\n",
            "Starting training epoch 6/10\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 1.5311 - accuracy: 0.3724\n",
            "Time used for epoch 6: 0 m 20 s\n",
            "Evaluating on dev set after epoch 6/10:\n",
            "Model BLEU score: 4.54\n",
            "Time used for evaluate on dev set: 0 m 6 s\n",
            "Starting training epoch 7/10\n",
            "240/240 [==============================] - 15s 61ms/step - loss: 1.4954 - accuracy: 0.3794\n",
            "Time used for epoch 7: 0 m 14 s\n",
            "Evaluating on dev set after epoch 7/10:\n",
            "Model BLEU score: 4.87\n",
            "Time used for evaluate on dev set: 0 m 6 s\n",
            "Starting training epoch 8/10\n",
            "240/240 [==============================] - 15s 61ms/step - loss: 1.4647 - accuracy: 0.3847\n",
            "Time used for epoch 8: 0 m 20 s\n",
            "Evaluating on dev set after epoch 8/10:\n",
            "Model BLEU score: 5.05\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Starting training epoch 9/10\n",
            "240/240 [==============================] - 15s 61ms/step - loss: 1.4383 - accuracy: 0.3892\n",
            "Time used for epoch 9: 0 m 14 s\n",
            "Evaluating on dev set after epoch 9/10:\n",
            "Model BLEU score: 5.03\n",
            "Time used for evaluate on dev set: 0 m 6 s\n",
            "Starting training epoch 10/10\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 1.4158 - accuracy: 0.3922\n",
            "Time used for epoch 10: 0 m 20 s\n",
            "Evaluating on dev set after epoch 10/10:\n",
            "Model BLEU score: 5.08\n",
            "Time used for evaluate on dev set: 0 m 6 s\n",
            "Training finished!\n",
            "Time used for training: 4 m 3 s\n",
            "Evaluating on test set:\n",
            "Model BLEU score: 5.65\n",
            "Time used for evaluate on test set: 0 m 6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample output"
      ],
      "metadata": {
        "id": "jjaHUPg-1du1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_examples(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMsL4GwMzMfk",
        "outputId": "fd724b62-5034-4240-8bde-ca4321088e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 5.65\n",
            "example:1\n",
            "Source sentence: trích dẫn thứ hai đến từ người đứng đầu cơ quan quản lý dịch vụ tài chính vương quốc anh .         \n",
            "Predicted translation: the <unk> <unk> , the <unk> <unk> , and the <unk> <unk> <unk> <unk> <unk> .\n",
            "Actual translation: the second quote is from the head of the u.k. financial services <unk> .\n",
            "example:2\n",
            "Source sentence: chuyện trở nên tồi tệ hơn .                       \n",
            "Predicted translation: it &apos;s really quite <unk> .\n",
            "Actual translation: it gets worse .\n",
            "example:3\n",
            "Source sentence: chuyện gì đang diễn ra ở đây ? sao chuyện này lại có thể ?               \n",
            "Predicted translation: what &apos;s happening today ? what is happening ?\n",
            "Actual translation: what &apos;s happening here ? how can this be possible ?\n",
            "example:4\n",
            "Source sentence: thật không may , câu trả lời là đúng vậy đấy .                  \n",
            "Predicted translation: in fact , it &apos;s not a <unk> .\n",
            "Actual translation: unfortunately , the answer is yes .\n",
            "example:5\n",
            "Source sentence: nhưng mà , có một giải pháp rất thú vị đến từ lĩnh vực được biết đến như là một môn học của sự phức hợp .  \n",
            "Predicted translation: but there &apos;s a very <unk> <unk> , and it &apos;s a <unk> <unk> .\n",
            "Actual translation: but there &apos;s an <unk> solution which is coming from what is known as the science of <unk> .\n",
            "example:6\n",
            "Source sentence: để giải thích nó là gì , và nó có ý nghĩa thế nào , xin cho phép tôi kể nhanh một chút chuyện cũ .    \n",
            "Predicted translation: i want to talk about is that i &apos;m going to talk about is that i &apos;m going to do that .\n",
            "Actual translation: to explain what this means and what this thing is , please let me quickly take a couple of steps back .\n",
            "example:7\n",
            "Source sentence: tôi đã đến với vật lý một cách tình cờ .                   \n",
            "Predicted translation: i &apos;m <unk> to <unk> <unk> .\n",
            "Actual translation: i ended up in physics by accident .\n",
            "example:8\n",
            "Source sentence: tóm lại , bạn có thể nghĩ\n",
            "Predicted translation: and you can see that you can see that .\n",
            "Actual translation: in a <unk> , you can think of physics as <unk> .\n",
            "example:9\n",
            "Source sentence: bạn lấy ra một đoạn thực tại bạn muốn tìm hiểu và bạn dịch nó sang ngôn ngữ toán học .         \n",
            "Predicted translation: you know , you can see that you can see that the <unk> is not <unk> .\n",
            "Actual translation: so you take a <unk> of reality you want to understand and you <unk> it into <unk> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlMDC3DJi12c"
      },
      "source": [
        "## **Training with Attention**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cQKwvFqurVY"
      },
      "source": [
        "The inputs to the attention layer are encoder and decoder outputs. The attention mechanism:\n",
        "1. Computes a score (a luong score) for each source word\n",
        "2. Weights the words by their luong scores.\n",
        "3. Concatenates the wieghted encoder representation with the decoder_ouput.\n",
        "This new decoder output will now be the input to the decoder_dense layer. \n",
        "\n",
        "Task 3 description in the doc file outlines the steps for this in detail. Once you have completed this Task, you are now ready to train with attention. Training time will be no more than 10 minutes using a GPU and you should get a bleu score of about 15."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "JSjxPpGR1jfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clear session prior to creating the architecture\n",
        "tf.keras.backend.clear_session()\n",
        "model_attention = NmtModel(source_lang_dict, target_lang_dict,True)\n",
        "model_attention.build()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9g-ULZpsVoR",
        "outputId": "469fee1d-e9ea-475a-c472-e52af19055d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of tokens in source: 2034, number of tokens in target:2506\n",
            "Task 1(a): Creating the embedding lookups...\n",
            "\n",
            "Task 1(b): Looking up source and target words...\n",
            "\n",
            "Task 1(c): Creating an encoder\n",
            "WARNING:tensorflow:Layer decoder_LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "\t\t\t\t\t\t Train Model Summary.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_source (Embedding)   (None, None, 100)    203400      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dropout_source_embedding (Drop  (None, None, 100)   0           ['embedding_source[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_target (Embedding)   (None, None, 100)    250600      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " encoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_source_embedding[0][0]'\n",
            "                                 (None, 200),                    ]                                \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " dropout_target_embedding (Drop  (None, None, 100)   0           ['embedding_target[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " decoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_target_embedding[0][0]'\n",
            "                                 (None, 200),                    , 'encoder_LSTM[0][1]',          \n",
            "                                 (None, 200)]                     'encoder_LSTM[0][2]']           \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  (None, None, 400)   0           ['encoder_LSTM[0][0]',           \n",
            " r)                                                               'decoder_LSTM[0][0]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 2506)   1004906     ['attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,940,506\n",
            "Trainable params: 1,940,506\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_source (Embedding  (None, None, 100)        203400    \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_source_embedding (D  (None, None, 100)        0         \n",
            " ropout)                                                         \n",
            "                                                                 \n",
            " encoder_LSTM (LSTM)         [(None, None, 200),       240800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 444,200\n",
            "Trainable params: 444,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Putting together the decoder states\n",
            "\t\t\t\t\t\t Decoder Inference Model summary\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_target (Embedding)   (None, None, 100)    250600      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_target_embedding (Drop  (None, None, 100)   0           ['embedding_target[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, None, 200)]  0           []                               \n",
            "                                                                                                  \n",
            " decoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_target_embedding[0][0]'\n",
            "                                 (None, 200),                    , 'input_3[0][0]',               \n",
            "                                 (None, 200)]                     'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  (None, None, 400)   0           ['input_5[0][0]',                \n",
            " r)                                                               'decoder_LSTM[1][0]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 2506)   1004906     ['attention_layer[1][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,496,306\n",
            "Trainable params: 1,496,306\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and test evaluation "
      ],
      "metadata": {
        "id": "YzM3PZw51oFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_attention.train(train_data,dev_data,test_data,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAdMWyzRsnjS",
        "outputId": "5e083560-dee4-47c6-8fe3-07170515de52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training epoch 1/10\n",
            "240/240 [==============================] - 20s 65ms/step - loss: 2.0651 - accuracy: 0.2685\n",
            "Time used for epoch 1: 0 m 20 s\n",
            "Evaluating on dev set after epoch 1/10:\n",
            "Model BLEU score: 5.49\n",
            "Time used for evaluate on dev set: 0 m 8 s\n",
            "Starting training epoch 2/10\n",
            "240/240 [==============================] - 16s 65ms/step - loss: 1.5697 - accuracy: 0.4042\n",
            "Time used for epoch 2: 0 m 20 s\n",
            "Evaluating on dev set after epoch 2/10:\n",
            "Model BLEU score: 10.99\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Starting training epoch 3/10\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 1.3137 - accuracy: 0.4621\n",
            "Time used for epoch 3: 0 m 20 s\n",
            "Evaluating on dev set after epoch 3/10:\n",
            "Model BLEU score: 13.50\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Starting training epoch 4/10\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 1.1637 - accuracy: 0.4944\n",
            "Time used for epoch 4: 0 m 15 s\n",
            "Evaluating on dev set after epoch 4/10:\n",
            "Model BLEU score: 15.02\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Starting training epoch 5/10\n",
            "240/240 [==============================] - 15s 64ms/step - loss: 1.0695 - accuracy: 0.5161\n",
            "Time used for epoch 5: 0 m 15 s\n",
            "Evaluating on dev set after epoch 5/10:\n",
            "Model BLEU score: 15.25\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Starting training epoch 6/10\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 1.0048 - accuracy: 0.5320\n",
            "Time used for epoch 6: 0 m 15 s\n",
            "Evaluating on dev set after epoch 6/10:\n",
            "Model BLEU score: 14.98\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Starting training epoch 7/10\n",
            "240/240 [==============================] - 15s 64ms/step - loss: 0.9568 - accuracy: 0.5452\n",
            "Time used for epoch 7: 0 m 15 s\n",
            "Evaluating on dev set after epoch 7/10:\n",
            "Model BLEU score: 15.92\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Starting training epoch 8/10\n",
            "240/240 [==============================] - 15s 64ms/step - loss: 0.9174 - accuracy: 0.5560\n",
            "Time used for epoch 8: 0 m 20 s\n",
            "Evaluating on dev set after epoch 8/10:\n",
            "Model BLEU score: 15.84\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Starting training epoch 9/10\n",
            "240/240 [==============================] - 16s 66ms/step - loss: 0.8887 - accuracy: 0.5644\n",
            "Time used for epoch 9: 0 m 15 s\n",
            "Evaluating on dev set after epoch 9/10:\n",
            "Model BLEU score: 15.72\n",
            "Time used for evaluate on dev set: 0 m 7 s\n",
            "Starting training epoch 10/10\n",
            "240/240 [==============================] - 16s 66ms/step - loss: 0.8634 - accuracy: 0.5716\n",
            "Time used for epoch 10: 0 m 20 s\n",
            "Evaluating on dev set after epoch 10/10:\n",
            "Model BLEU score: 15.52\n",
            "Time used for evaluate on dev set: 0 m 6 s\n",
            "Training finished!\n",
            "Time used for training: 4 m 11 s\n",
            "Evaluating on test set:\n",
            "Model BLEU score: 16.25\n",
            "Time used for evaluate on test set: 0 m 6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample output"
      ],
      "metadata": {
        "id": "ditQfaE31sXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_examples(model_attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsDKHotrw7yF",
        "outputId": "2c221764-665e-4261-be4c-00baaab55ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 16.25\n",
            "example:1\n",
            "Source sentence: trích dẫn thứ hai đến từ người đứng đầu cơ quan quản lý dịch vụ tài chính vương quốc anh .         \n",
            "Predicted translation: the second path came from the head of the <unk> <unk> of the <unk> england .\n",
            "Actual translation: the second quote is from the head of the u.k. financial services <unk> .\n",
            "example:2\n",
            "Source sentence: chuyện trở nên tồi tệ hơn .                       \n",
            "Predicted translation: so obviously it &apos;s worse .\n",
            "Actual translation: it gets worse .\n",
            "example:3\n",
            "Source sentence: chuyện gì đang diễn ra ở đây ? sao chuyện này lại có thể ?               \n",
            "Predicted translation: what &apos;s going on here ? why can you ?\n",
            "Actual translation: what &apos;s happening here ? how can this be possible ?\n",
            "example:4\n",
            "Source sentence: thật không may , câu trả lời là đúng vậy đấy .                  \n",
            "Predicted translation: unfortunately , the answer is correct .\n",
            "Actual translation: unfortunately , the answer is yes .\n",
            "example:5\n",
            "Source sentence: nhưng mà , có một giải pháp rất thú vị đến từ lĩnh vực được biết đến như là một môn học của sự phức hợp .  \n",
            "Predicted translation: but , there &apos;s a solution to be very interesting to know that the <unk> is sort of <unk> .\n",
            "Actual translation: but there &apos;s an <unk> solution which is coming from what is known as the science of <unk> .\n",
            "example:6\n",
            "Source sentence: để giải thích nó là gì , và nó có ý nghĩa thế nào , xin cho phép tôi kể nhanh một chút chuyện cũ .    \n",
            "Predicted translation: so , what it explain it , and it means , and it means , it means a <unk> .\n",
            "Actual translation: to explain what this means and what this thing is , please let me quickly take a couple of steps back .\n",
            "example:7\n",
            "Source sentence: tôi đã đến với vật lý một cách tình cờ .                   \n",
            "Predicted translation: i went to a physics of a <unk> .\n",
            "Actual translation: i ended up in physics by accident .\n",
            "example:8\n",
            "Source sentence: tóm lại , bạn có thể nghĩ\n",
            "Predicted translation: to <unk> , you can think about the physics .\n",
            "Actual translation: in a <unk> , you can think of physics as <unk> .\n",
            "example:9\n",
            "Source sentence: bạn lấy ra một đoạn thực tại bạn muốn tìm hiểu và bạn dịch nó sang ngôn ngữ toán học .         \n",
            "Predicted translation: you get to get a real <unk> in you to find and you &apos;re going to get into a math .\n",
            "Actual translation: so you take a <unk> of reality you want to understand and you <unk> it into <unk> .\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "7001_2021_22_Lab5_6_NMT_Final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}